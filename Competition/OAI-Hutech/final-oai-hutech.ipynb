{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":100115,"databundleVersionId":12010971,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install timm==0.9.12 albumentations==1.4.0 opencv-python-headless -U ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:09:27.811623Z","iopub.execute_input":"2025-04-25T04:09:27.812096Z","iopub.status.idle":"2025-04-25T04:10:56.523088Z","shell.execute_reply.started":"2025-04-25T04:09:27.812064Z","shell.execute_reply":"2025-04-25T04:10:56.522128Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"### START: CÁC KHAI BÁO CHÍNH - KHÔNG THAY ĐỔI ###\nSEED = 25  # Số seed (Ban tổ chức sẽ công bố & thay đổi vào lúc chấm)\n# Đường dẫn đến thư mục train\n# (đúng theo cấu trúc gồm 4 thư mục cho 4 classes của ban tổ chức)\nTRAIN_DATA_DIR_PATH = '/kaggle/input/ck-aio-hutech/oai_data/train'\n# Đường dẫn đến thư mục test\nTEST_DATA_DIR_PATH = '/kaggle/input/ck-aio-hutech/oai_data/test'\n### END: CÁC KHAI BÁO CHÍNH - KHÔNG THAY ĐỔI ###\n\n\n### START: CÁC THƯ VIỆN IMPORT ###\n# Lưu ý: các thư viện & phiên bản cài đặt vui lòng để trong requirements.txt\n#───────────────────────────────────────────────────────────────  \n# 1) Imports & basic set‑up  \n#───────────────────────────────────────────────────────────────  \nimport unicodedata\nimport os, gc, random, warnings  \nfrom pathlib import Path  \nfrom collections import Counter  \n\nimport numpy as np\nimport pandas as pd  \nfrom PIL import Image  \n\nimport torch, torch.nn as nn  \nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  \nfrom sklearn.model_selection import StratifiedKFold  \n\nimport albumentations as A  \nfrom albumentations.pytorch import ToTensorV2  \nimport timm\nwarnings.filterwarnings(\"ignore\")  \n### END: CÁC THƯ VIỆN IMPORT ###\n\n\n### START: SEEDING EVERYTHING - KHÔNG THAY ĐỔI ###\n# Seeding nhằm đảm bảo kết quả sẽ cố định\n# và không ngẫu nhiên ở các lần chạy khác nhau\n# Set seed for random\nrandom.seed(SEED)\n# Set seed for numpy\nnp.random.seed(SEED)\n# Set seed for torch\ntorch.manual_seed(SEED)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.manual_seed_all(SEED)\n### END: SEEDING EVERYTHING - KHÔNG THAY ĐỔI ###\n\n\n### START: ĐỊNH NGHĨA & CHẠY HUẤN LUYỆN MÔ HÌNH ###\n#───────────────────────────────────────────────────────────────  \n# 2) Paths  \n#───────────────────────────────────────────────────────────────  \nTRAIN_DIR = TRAIN_DATA_DIR_PATH \nTEST_DIR  = TEST_DATA_DIR_PATH\n\n#───────────────────────────────────────────────────────────────  \n# 3) Label map  \n#───────────────────────────────────────────────────────────────  \nlabel_map = {  \n    unicodedata.normalize('NFC', \"đông cô\"): 0,  \n    unicodedata.normalize('NFC', \"tai mèo\"): 1,  \n    unicodedata.normalize('NFC', \"tuyết khô\"): 2  \n}   \nidx2cls = {v:k for k,v in label_map.items()}  \nN_CLASS = len(label_map)  \n\n#───────────────────────────────────────────────────────────────  \n# 4) Collect image paths  \n#───────────────────────────────────────────────────────────────  \ndef collect(root):  \n    p,l = [],[]  \n    for folder in os.listdir(root):  \n        folder_norm = unicodedata.normalize('NFC', folder.lower().strip())  \n        lbl = label_map[folder_norm]  \n        for f in os.listdir(os.path.join(root, folder)):  \n            p.append(os.path.join(root, folder, f)); l.append(lbl)  \n    return p,l  \n\ntrain_paths, train_labels = collect(TRAIN_DIR)  \ntest_paths  = [os.path.join(TEST_DIR, f) for f in sorted(os.listdir(TEST_DIR))]  \n\nprint(\"Train =\", len(train_paths), \" Test =\", len(test_paths))  \nprint(\"Train distribution:\", Counter(train_labels))  \n\n#───────────────────────────────────────────────────────────────  \n# 5) 5‑fold (use fold‑0 for validation)  \n#───────────────────────────────────────────────────────────────  \nskf = StratifiedKFold(5, shuffle=True, random_state=SEED)  \ntr_idx, vl_idx = list(skf.split(train_paths, train_labels))[0]  \n\n#───────────────────────────────────────────────────────────────  \n# 6) Augmentations  (RandAugment removed)  \n#───────────────────────────────────────────────────────────────  \nIMG_SZ = 224  \ntrain_tf = A.Compose([  \n    A.RandomResizedCrop(IMG_SZ, IMG_SZ, scale=(0.6,1.0), ratio=(0.8,1.2)),  \n    A.HorizontalFlip(p=0.5),  \n    A.VerticalFlip(p=0.3),  \n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15,  \n                       rotate_limit=20, border_mode=0, p=0.5),  \n    A.HueSaturationValue(10,15,10, p=0.3),  \n    A.RandomBrightnessContrast(0.15,0.15, p=0.4),  \n    A.CoarseDropout(max_holes=4, max_height=IMG_SZ//10,  \n                    max_width=IMG_SZ//10, p=0.3),  \n    A.ToFloat(max_value=255.0), ToTensorV2()  \n])  \nval_tf = A.Compose([A.Resize(IMG_SZ, IMG_SZ),  \n                    A.ToFloat(max_value=255.0), ToTensorV2()])\n\n#───────────────────────────────────────────────────────────────  \n# 7) Dataset / loader helpers  \n#───────────────────────────────────────────────────────────────  \nclass ImgDS(Dataset):  \n    def __init__(self, paths, labels=None, tf=None):  \n        self.p, self.y, self.tf = paths, labels, tf  \n    def __len__(self): return len(self.p)  \n    def __getitem__(self, i):  \n        img = Image.open(self.p[i]).convert(\"RGB\")  \n        img = self.tf(image=np.array(img))[\"image\"]  \n        if self.y is None: return img  \n        return img, self.y[i]  \n\ndef make_loader(idxs, tf, bs, train=True):  \n    paths  = [train_paths[i] for i in idxs]  \n    labels = [train_labels[i] for i in idxs]  \n    ds = ImgDS(paths, labels, tf)  \n    if train:  \n        sampler = WeightedRandomSampler(np.ones(len(labels)), len(labels))  \n        return DataLoader(ds, bs, sampler=sampler,  \n                          num_workers=2, pin_memory=True)  \n    return DataLoader(ds, bs*2, shuffle=False,  \n                      num_workers=2, pin_memory=True)  \n\nBATCH = 32  \ntr_loader = make_loader(tr_idx, train_tf, BATCH, True)  \nvl_loader = make_loader(vl_idx, val_tf,   BATCH, False)  \n\n#───────────────────────────────────────────────────────────────  \n# 8) ViT‑small‑16 model  \n#───────────────────────────────────────────────────────────────  \nmodel = timm.create_model(  \n    \"vit_small_patch16_224\",  \n    pretrained=True,  \n    num_classes=N_CLASS,  \n    drop_path_rate=0.1  \n).to(DEVICE)  \n\n#───────────────────────────────────────────────────────────────  \n# 9) Optimiser, loss, schedule  \n#───────────────────────────────────────────────────────────────  \nEPOCHS = 12 \nLR  = 5e-5      # learning rate\nWD  = 1e-4      # weight decay\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)    # label smoothing = 0.1\nopt  = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)  \nsched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS*len(tr_loader))  \n\nos.makedirs(\"BEST_MODEL\", exist_ok=True) # create a directory to save the best model\n\nbest_acc = 0  \nfor ep in range(1, EPOCHS+1):  \n    model.train(); run=0  \n    for xb,yb in tr_loader:  \n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)  \n        opt.zero_grad()  \n        loss = criterion(model(xb), yb)  \n        loss.backward(); opt.step(); sched.step()  \n        run += loss.item()*yb.size(0)  \n    tr_loss = run/len(tr_loader.dataset)  \n\n    model.eval(); corr=tot=0  \n    with torch.no_grad():  \n        for xb,yb in vl_loader:  \n            xb, yb = xb.to(DEVICE), yb.to(DEVICE)  \n            pred = model(xb).argmax(1)  \n            corr += (pred==yb).sum().item(); tot += yb.size(0)  \n    acc = 100*corr/tot\n    best_acc=max(best_acc,acc)  \n    print(f\"Epoch {ep:02d}/{EPOCHS}  train‑loss: {tr_loss:.4f}  val‑acc: {acc:.2f}\")  \n\nprint(f\"Best val-accuracy: {best_acc:.2f}\")  \n\n#───────────────────────────────────────────────────────────────  \n# 10) Quick fine‑tune on full data  \n#───────────────────────────────────────────────────────────────  \nprint(\"\\nQuick fine-tune on full data...\")\nfull_loader = DataLoader(  \n    ImgDS(train_paths, train_labels, train_tf),  \n    batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)  \nopt = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=WD)  \nfor ep in range(1,6):  \n    model.train(); run=0  \n    for xb,yb in full_loader:  \n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)  \n        opt.zero_grad()  \n        loss = criterion(model(xb), yb)  \n        loss.backward(); opt.step()  \n        run += loss.item()*yb.size(0)  \n    print(f\"[Full] Epoch {ep}/5  loss {run/len(full_loader.dataset):.4f}\")  \n    \n#───────────────────────────────────────────────────────────────  \n# 11) Inference  \n#───────────────────────────────────────────────────────────────  \ntest_loader = DataLoader(ImgDS(test_paths, tf=val_tf),  \n                         batch_size=BATCH*2, shuffle=False,  \n                         num_workers=2, pin_memory=True)  \nmodel.eval(); preds=[]  \nwith torch.no_grad():  \n    for xb in test_loader:  \n        preds.append(model(xb.to(DEVICE)).softmax(1).argmax(1).cpu().numpy())  \npred = np.concatenate(preds)  \n\nprint(\"\\nPredicted distribution:\")  \nfor i,c in enumerate(np.bincount(pred, minlength=N_CLASS)):  \n    print(f\"{i}: {idx2cls[i]:25} {c}\")  \n    \n### END: ĐỊNH NGHĨA & CHẠY HUẤN LUYỆN MÔ HÌNH ###\n\n\n### START: THỰC NGHIỆM & XUẤT FILE KẾT QUẢ RA CSV ###\n#───────────────────────────────────────────────────────────────  \n# 12) Submission  \n#───────────────────────────────────────────────────────────────  \n# os.makedirs(\"output\", exist_ok=True)  \nimage_names = [os.path.splitext(os.path.basename(path))[0] for path in test_paths]   \nsubmission_df = pd.DataFrame({  \n    \"image_name\": image_names,  \n    \"label\": pred  \n})  \nsubmission_df.to_csv(\"/kaggle/working/results.csv\", index=False)   \nprint(\"\\nFile results.csv saved!\") \n\n### END: THỰC NGHIỆM & XUẤT FILE KẾT QUẢ RA CSV ###","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T04:18:21.786517Z","iopub.execute_input":"2025-04-25T04:18:21.787354Z","iopub.status.idle":"2025-04-25T04:21:35.328670Z","shell.execute_reply.started":"2025-04-25T04:18:21.787325Z","shell.execute_reply":"2025-04-25T04:21:35.327925Z"}},"outputs":[{"name":"stdout","text":"Train = 1050  Test = 450\nTrain distribution: Counter({1: 350, 0: 350, 2: 350})\nEpoch 01/12  train‑loss: 0.6373  val‑acc: 97.62\nEpoch 02/12  train‑loss: 0.4004  val‑acc: 96.19\nEpoch 03/12  train‑loss: 0.3629  val‑acc: 98.57\nEpoch 04/12  train‑loss: 0.3484  val‑acc: 99.52\nEpoch 05/12  train‑loss: 0.3321  val‑acc: 99.52\nEpoch 06/12  train‑loss: 0.3276  val‑acc: 100.00\nEpoch 07/12  train‑loss: 0.3180  val‑acc: 99.52\nEpoch 08/12  train‑loss: 0.3198  val‑acc: 100.00\nEpoch 09/12  train‑loss: 0.3179  val‑acc: 99.52\nEpoch 10/12  train‑loss: 0.3133  val‑acc: 99.52\nEpoch 11/12  train‑loss: 0.3103  val‑acc: 99.52\nEpoch 12/12  train‑loss: 0.3126  val‑acc: 99.52\nBest val-accuracy: 100.00\n\nQuick fine-tune on full data...\n[Full] Epoch 1/5  loss 0.3165\n[Full] Epoch 2/5  loss 0.3103\n[Full] Epoch 3/5  loss 0.3076\n[Full] Epoch 4/5  loss 0.3059\n[Full] Epoch 5/5  loss 0.3065\n\nPredicted distribution:\n0: đông cô                   152\n1: tai mèo                   148\n2: tuyết khô                 150\n\nFile results.csv saved!\n","output_type":"stream"}],"execution_count":5}]}